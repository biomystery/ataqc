#!/usr/bin/env python

"""Main executable for ATAqC
"""

import os
import sys
import argparse
import json
import logging
import time
import pkg_resources

# added to deal with library backend issues
import matplotlib
matplotlib.use("Agg")


from collections import OrderedDict

from ataqc.util.io import sample_sheet_to_dict
from ataqc.util.io import load_json_to_string_dict

from ataqc.reads import AlignedReads
from ataqc.peaks import Peaks
from ataqc import integrative
from ataqc.qc import run_qc
from ataqc.viz import write_html
from ataqc.viz import write_text


def parse_args():
    """Parse arguments to go into ataqc
    """
    parser = argparse.ArgumentParser(description="ATAqC: ATAC-seq QC package")
    subparsers = parser.add_subparsers(dest="subcommand_name")

    # run everything parser
    add_run_all_parser(subparsers)

    # run tss enrichment only parser
    add_run_tss_parser(subparsers)
    
    # run legacy parser
    add_run_legacy_parser(subparsers)
    
    args = parser.parse_args()

    return args


def add_output_options(parser, out_dir="./"):
    """Add an output directory and prefix if desired
    """
    parser.add_argument(
        "-o", "--out_dir", dest="out_dir", type=str,
        default=out_dir,
        help = "Output directory (default: current)")
    parser.add_argument(
        '--prefix', required=True,
        help='prefix to attach onto file names')

    return



def add_run_all_parser(subparsers):
    """Full run utilizing sample sheet
    """
    argparser_runall = subparsers.add_parser(
        "run_all",
        help="run all QC; requires data spreadsheet")

    argparser_runall.add_argument("--samples", required=True, help="tab delimited data sheet")
    argparser_runall.add_argument("--species", required=True, help="species json file")
    argparser_runall.add_argument("--thresholds", default=pkg_resources.resource_filename('ataqc', 'data/thresholds.json'),
                                  help="qc thresholds json file")
    argparser_runall.add_argument("--encode", action="store_true", help="only run ENCODE QC")

    add_output_options(argparser_runall)
    
    return


def add_run_tss_parser(subparsers):
    """Just run TSS enrichment
    """
    argparser_tss = subparsers.add_parser(
        "run_tss",
        help="run TSS enrichment only")

    argparser_tss.add_argument("--species", required=True, help="species json file")
    argparser_tss.add_argument("--genome", required=True, help="which annotation set to use")
    argparser_tss.add_argument("--final_bam", help="Final filtered BAM file")

    add_output_options(argparser_tss)
    
    return


def add_run_legacy_parser(subparsers):
    """Allows running by putting each individual file in as an arg
    """
    argparser_legacy = subparsers.add_parser(
        "run_legacy",
        help="run legacy mode (every file as input arg)")

    argparser_legacy.add_argument("--species", required=True, help="species json file")
    argparser_legacy.add_argument("--genome", required=True, help="which annotation set to use")
    argparser_legacy.add_argument("--thresholds", default=pkg_resources.resource_filename('ataqc', 'data/thresholds.json'),
                                  help="qc thresholds json file")
    argparser_legacy.add_argument('--name', help='Name of sample')
    argparser_legacy.add_argument('--fastq1', help='First set of reads if paired end, or the single end reads')
    argparser_legacy.add_argument('--fastq2', help='Second set of reads if paired end')
    argparser_legacy.add_argument('--raw_bam', help='BAM file from the aligner')
    argparser_legacy.add_argument('--alignment_log', help='Alignment log')
    argparser_legacy.add_argument('--dup_log', help='Picard duplicate metrics file')
    argparser_legacy.add_argument('--pbc_log', help='ENCODE library complexity metrics file')
    argparser_legacy.add_argument('--final_bam', help='Final filtered BAM file')
    argparser_legacy.add_argument('--final_bed', help='Final filtered alignments in BED format')
    argparser_legacy.add_argument('--bigwig', help='Final bigwig')
    argparser_legacy.add_argument('--peaks', nargs="+", help='Raw Peak file')
    argparser_legacy.add_argument('--use_sambamba_markdup', action='store_true', help='Use sambamba markdup instead of Picard')

    argparser_legacy.add_argument("--encode", action="store_true", help="only run ENCODE QC")

    add_output_options(argparser_legacy)
    
    return


def run_checks():
    """Just for if ENCODE, there are certain required files?
    """
    # TODO

    return


def run_metrics(sample, species_files, out_dir, prefix, encode=False):
    """Run metrics
    """
    os.system("mkdir -p {}".format(out_dir))
    prefix = "{}/{}".format(out_dir, prefix)
    metrics = {}

    # TODO at some point add in fastq QC
    
    
    # run BAM file QC
    logging.info("getting metrics on BAM files...")
    if sample["raw_bam"] is not None:
        raw_aligned_bam = AlignedReads(sample["raw_bam"], False, species_files, prefix, dup_log=sample["dup_log"], pbc_log=sample["pbc_log"])
        metrics['raw_bam'] = raw_aligned_bam.run_metrics(encode=encode)
        
    if sample["final_bam"] is not None:
        final_aligned_bam = AlignedReads(sample['final_bam'], True, species_files, prefix)
        metrics['final_bam'] = final_aligned_bam.run_metrics(encode=encode)

    # run peaks QC
    logging.info("getting metrics on peak files...")
    metrics['peaks'] = {}
    for peak_key in sample['peaks'].keys():
        peak_bed = Peaks(sample['peaks'][peak_key], peak_key)
        metrics['peaks'][peak_key] = peak_bed.run_metrics(encode=encode)

    # run integrative QC
    # this module operates exclusively on the metrics dict
    logging.info("getting integrative metrics...")
    metrics['integrative'] = integrative.run_metrics(metrics, sample, species_files, prefix, encode)

    return metrics


def run_pipeline(sample, species_files, thresholds, out_dir, prefix, encode=False):
    """Run metrics, run QC checks, output to html and text
    """
    metrics = run_metrics(
        sample,
        species_files,
        out_dir,
        prefix,
        encode=encode)
    qc_groups = run_qc(
        metrics,
        thresholds,
        sample,
        "{}/{}".format(out_dir, prefix),
        sample["name"],
        encode)
    write_html(
        qc_groups,
        "{}/{}".format(out_dir, prefix),
        sample["name"])
    write_text(
        qc_groups,
        "{}/{}".format(out_dir, prefix),
        sample["name"])

    return


def track_runs(args):
    """track command and github commit
    """
    # keeps track of restores (or different commands) in folder
    logging_file = '{0}/{1}.ataqc.log'.format(args.out_dir, args.prefix)
    
    # track github commit
    git_repo_path = os.path.dirname(os.path.realpath(__file__))
    os.system('echo "commit:" > {0}'.format(logging_file))
    os.system('git -C {0} rev-parse HEAD >> {1}'.format(git_repo_path, logging_file))
    os.system('echo "" >> {0}'.format(logging_file))
    
    # write out the command
    with open(logging_file, 'a') as f:
        f.write(' '.join(sys.argv)+'\n\n')
        
    return logging_file


def main():
    """Main function for running ataqc functions
    """
    args = parse_args()
    os.system("mkdir -p {}".format(args.out_dir))
    logging_file = track_runs(args)
    logging.basicConfig(filename=logging_file, level=logging.DEBUG)
    
    subcommand = args.subcommand_name
    start = time.time()

    if subcommand == "run_all":
        # convert data sheet into a dict of arguments, then use run_legacy
        species_files = load_json_to_string_dict(args.species)
        thresholds = load_json_to_string_dict(args.thresholds)
        samples = sample_sheet_to_dict(args.samples)

        for sample in samples:
            run_pipeline(
                sample,
                species_files[sample["genome"]],
                thresholds[sample["genome"]],
                args.out_dir,
                args.prefix,
                encode=args.encode)
            
    elif subcommand == "run_tss":
        species_files = load_json_to_string_dict(args.species)
        final_aligned_bam = AlignedReads(args.final_bam, True, species_files[args.genome], args.prefix)
        tss_enrich = final_aligned_bam.tss_enrichment()
        print "TSS Enrichment: {}".format(tss_enrich)

    elif subcommand == "run_legacy":
        species_files = load_json_to_string_dict(args.species)
        thresholds = load_json_to_string_dict(args.thresholds)

        # set up sample here:
        sample = OrderedDict([
            ("name", args.name),
            ("genome", args.genome),
            ("fastq1", args.fastq1),
            ("fastq2", args.fastq2),
            ("raw_bam", args.raw_bam),
            ("alignment_log", args.alignment_log),
            ("dup_log", args.dup_log),
            ("pbc_log", args.pbc_log),
            ("final_bam", args.final_bam),
            ("final_bed", args.final_bed),
            ("bigwig", args.bigwig),
            ("peaks", OrderedDict([peak.split("=") for peak in args.peaks]))
        ])

        # run sample
        run_pipeline(
            sample,
            species_files[sample["genome"]],
            thresholds[sample["genome"]],
            args.out_dir,
            args.prefix,
            encode=args.encode)
        
    end = time.time()
    logging.info("DONE: {}".format(end - start))

    return


if __name__ == "__main__":
    main()
